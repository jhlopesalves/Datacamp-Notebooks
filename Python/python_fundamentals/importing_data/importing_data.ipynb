{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f27e06",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO IMPORTING DATA IN PYTHON\n",
    "\n",
    "One of the core strengths of Python as a data science, engineering, and automation language is its extensive capability to **import and export data** from a wide range of sources. Whether working with flat files, files produced by other software, or relational databases, Python provides robust tools to read, process, and write data efficiently.\n",
    "\n",
    "\n",
    "### Types of Data Sources\n",
    "\n",
    "#### 1. Flat Files\n",
    "\n",
    "- Text files (`.txt`)\n",
    "- Comma-Separated Values (`.csv`)\n",
    "- Tab-delimited files (`.tsv`)\n",
    "- These are the most common formats for raw or exported data.\n",
    "\n",
    "#### 2. Files from Other Software\n",
    "\n",
    "- Excel files (`.xlsx`, `.xls`)\n",
    "- SPSS, Stata, SAS\n",
    "- Binary formats and data from statistical or business software\n",
    "\n",
    "#### 3. Relational Databases\n",
    "\n",
    "- SQL-based databases: SQLite, PostgreSQL, MySQL, etc.\n",
    "- NoSQL and semi-structured sources (MongoDB, JSON, XML) can also be handled, but require different approaches.\n",
    "\n",
    "### Reading Text Files in Python\n",
    "\n",
    "The foundational tool for file I/O in Python is the built-in `open()` function, which provides an interface to interact with files in various modes:\n",
    "\n",
    "- `'r'` – read (default)\n",
    "- `'w'` – write (overwrites existing file)\n",
    "- `'a'` – append (adds to end of file)\n",
    "- `'b'` – binary (for non-text data)\n",
    "- `'t'` – text (default, for strings)\n",
    "\n",
    "#### Basic Pattern: Reading a Text File\n",
    "\n",
    "```python\n",
    "filename = 'data.txt'\n",
    "file = open(filename, mode='r')  # Open file for reading\n",
    "text = file.read()               # Read entire file contents as a single string\n",
    "file.close()                     # Always close the file to free resources\n",
    "```\n",
    "\n",
    "##### Why Close the File?\n",
    "\n",
    "- Closing the file releases system resources, flushes any buffered data, and avoids resource leaks.\n",
    "- Failing to close files, especially in long-running programs or scripts processing many files, can lead to subtle bugs or performance issues.\n",
    "\n",
    "### Writing to a Text File\n",
    "\n",
    "Writing data follows the same `open()` pattern, with mode set to `'w'` (write):\n",
    "\n",
    "```python\n",
    "filename = 'output.txt'\n",
    "file = open(filename, mode='w')  # Open file for writing (creates/overwrites)\n",
    "file.write(\"Hello, world!\\n\")    # Write text to file\n",
    "file.close()                     # Always close after writing\n",
    "```\n",
    "\n",
    "- Be aware that opening a file in write mode will erase its previous contents.\n",
    "\n",
    "### The Pythonic Way: Context Managers with `with`\n",
    "\n",
    "Using the `with` statement (context manager) is the **recommended, Pythonic approach** for file I/O. It ensures that the file is **automatically closed** when the block is exited, even if errors occur.\n",
    "\n",
    "```python\n",
    "with open('data.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "    # The file is open inside this block\n",
    "\n",
    "# Once outside, file is automatically closed\n",
    "```\n",
    "\n",
    "- Context managers improve reliability and code readability.\n",
    "- Works for both reading and writing (`'r'`, `'w'`, `'a'`, etc.).\n",
    "\n",
    "### Why These Techniques Matter\n",
    "\n",
    "- Data rarely comes in a single, ready-to-use format. Mastering Python’s I/O enables seamless integration with diverse data sources and downstream workflows.\n",
    "- Robust file handling practices (closing files, using context managers) prevent bugs, resource leaks, and data corruption.\n",
    "- This foundational knowledge prepares you to work with higher-level libraries (such as `pandas`, `csv`, `json`, `openpyxl`, and `sqlalchemy`) for more sophisticated data import/export tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ffc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "\n",
      "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
      "little or no money in my purse, and nothing particular to interest me on\n",
      "shore, I thought I would sail about a little and see the watery part of\n",
      "the world. It is a way I have of driving off the spleen and regulating\n",
      "the circulation. Whenever I find myself growing grim about the mouth;\n",
      "whenever it is a damp, drizzly November in my soul; whenever I find\n",
      "myself involuntarily pausing before coffin warehouses, and bringing up\n",
      "the rear of every funeral I meet; and especially whenever my hypos get\n",
      "such an upper hand of me, that it requires a strong moral principle to\n",
      "prevent me from deliberately stepping into the street, and methodically\n",
      "knocking people's hats off--then, I account it high time to get to sea\n",
      "as soon as I can. This is my substitute for pistol and ball. With a\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\n",
      "take to the ship. There is nothing surprising in this. If they but knew\n",
      "it, almost all men in their degree, some time or other, cherish very\n",
      "nearly the same feelings towards the ocean with me.\n"
     ]
    }
   ],
   "source": [
    "# Open the file moby_dick.txt as read-only using a with statement and bind it to the variable file. Make sure to pass the filename enclosed in quotation marks ''.\n",
    "with open(\"data/moby_dick.txt\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63468e",
   "metadata": {},
   "source": [
    "### Importing text files line by line\n",
    "For large files, we may not want to print all of their content to the shell: you may wish to print only the first few lines. Enter the `.readline()` method, which allows you to do this. When a file called file is open, you can print out the first line by executing `file.readline()`. If you execute the same command again, the second line will print, and so on.\n",
    "\n",
    "In the introductory video, Hugo also introduced the concept of a context manager. He showed that you can bind a variable file by using a context manager construct:\n",
    "\n",
    "```python\n",
    "with open('huck_finn.txt') as file:\n",
    "```\n",
    "While still within this construct, the variable file will be bound to open('huck_finn.txt'); thus, to print the file to the shell, all the code you need to execute is:\n",
    "```python\n",
    "\n",
    "with open('huck_finn.txt') as file:\n",
    "    print(file.readline())\n",
    "```\n",
    "\n",
    "You'll now use these tools to print the first few lines of moby_dick.txt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "\n",
      "\n",
      "\n",
      "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Open moby_dick.txt using the with context manager and the variable file.\n",
    "with open(\"data/moby_dick.txt\") as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2ce11",
   "metadata": {},
   "source": [
    "## The Importance of Flat Files in Data Science\n",
    "\n",
    "### What Are Flat Files?\n",
    "\n",
    "**Flat files** are the most fundamental and widely used format for storing and exchanging tabular data. They consist of plain text files in which each row represents a single record (observation) and each column represents a feature or attribute (field) of that record. Because of their simplicity and universal compatibility, flat files underpin the vast majority of data workflows, data exchanges, and archival systems in both research and industry.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Record**: A row in the file; each record is an individual observation or entry.\n",
    "- **Field / Attribute**: A column; each field is a property, variable, or feature of the record.\n",
    "- **Header Row**: Typically, the first row in the file specifies the names of each column, providing context for the data.\n",
    "- **Delimiters**: Characters that separate fields within a record—commonly commas (`,`), tabs (`\\t`), or semicolons (`;`).\n",
    "\n",
    "### Common File Extensions and Formats\n",
    "\n",
    "- `.csv` – **Comma-Separated Values** (most common): Each field is separated by a comma.\n",
    "- `.txt` – **Plain Text**: Can be structured with various delimiters (commas, tabs, spaces).\n",
    "- `.tsv` – **Tab-Separated Values**: Each field is separated by a tab character.\n",
    "\n",
    "**Example CSV:**\n",
    "```\n",
    "name,age,score\n",
    "Alice,23,88\n",
    "Bob,21,93\n",
    "```\n",
    "\n",
    "**Example Tab-Delimited (.txt or .tsv):**\n",
    "```\n",
    "name    age    score\n",
    "Alice   23     88\n",
    "Bob     21     93\n",
    "```\n",
    "\n",
    "### Flat Files in Practice\n",
    "\n",
    "#### Why Are Flat Files So Important in Data Science?\n",
    "\n",
    "- **Universality**: Supported by virtually all software tools, programming languages, databases, and operating systems.\n",
    "- **Human-Readable**: Easily inspected and edited with basic text editors.\n",
    "- **Portable**: Easy to share, version, and archive.\n",
    "- **Simplicity**: No embedded formulas, macros, or binary structures—just raw data.\n",
    "- **Interoperability**: Used as the lingua franca for data exchange between disparate systems.\n",
    "\n",
    "#### Data Science Scenarios\n",
    "\n",
    "- **Data Acquisition**: Many open datasets (e.g., from Kaggle, UCI, government portals) are distributed as flat files.\n",
    "- **Intermediate Processing**: Data pipelines often use CSV or TSV as staging or checkpoint formats.\n",
    "- **Archival**: Flat files are ideal for long-term storage and future-proofing data against software obsolescence.\n",
    "\n",
    "### Importing Flat Files in Python\n",
    "\n",
    "Two primary packages dominate the import of flat files in the data science ecosystem:\n",
    "\n",
    "- **NumPy**: Optimised for fast import of numeric tabular data into arrays (ideal for large, homogeneous datasets).\n",
    "    - Functions like `numpy.loadtxt()` and `numpy.genfromtxt()` read in delimited text files.\n",
    "- **pandas**: The de facto library for data manipulation, capable of importing flat files with both numeric and string data, handling headers, missing values, and various delimiters.\n",
    "    - The `pandas.read_csv()` and `pandas.read_table()` functions are highly flexible and feature-rich.\n",
    "\n",
    "#### Importing Examples\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "numeric_data = np.loadtxt('data.csv', delimiter=',')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')  # Handles headers and mixed data types by default\n",
    "```\n",
    "\n",
    "### Beyond the Basics: Limitations and Considerations\n",
    "\n",
    "- **No Data Types**: All fields are read as text until parsed; you must specify or infer types post-import.\n",
    "- **No Metadata**: Flat files lack embedded information about units, relationships, or formats.\n",
    "- **Scalability**: Very large flat files can be unwieldy and require chunked or streamed processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfa550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
